{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stock Data Exploration\n",
    "\n",
    "This notebook explores the stock data collection and preprocessing pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from src.data.collectors.price_collector import PriceCollector\n",
    "from src.data.processors.technical_indicators import TechnicalIndicators\n",
    "from src.data.dataset import StockSequenceDataset\n",
    "from src.data.datamodule import StockDataModule\n",
    "\n",
    "# Set style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette('husl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize price collector\n",
    "collector = PriceCollector(cache_dir='../data/raw/price_cache')\n",
    "\n",
    "# Define parameters\n",
    "symbols = ['AAPL', 'MSFT', 'GOOGL', 'AMZN', 'TSLA']\n",
    "start_date = '2020-01-01'\n",
    "end_date = '2023-12-31'\n",
    "\n",
    "# Fetch data\n",
    "print(\"Fetching stock data...\")\n",
    "stock_data = collector.fetch_multiple_stocks(symbols, start_date, end_date)\n",
    "\n",
    "# Display basic info\n",
    "for symbol, df in stock_data.items():\n",
    "    print(f\"\\n{symbol}: {len(df)} trading days\")\n",
    "    print(f\"Date range: {df.index.min()} to {df.index.max()}\")\n",
    "    print(f\"Columns: {list(df.columns[:10])}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize price data\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, (symbol, df) in enumerate(stock_data.items()):\n",
    "    axes[i].plot(df.index, df['close'], label='Close', linewidth=2)\n",
    "    axes[i].fill_between(df.index, df['low'], df['high'], alpha=0.3, label='High-Low Range')\n",
    "    axes[i].set_title(f'{symbol} Price History')\n",
    "    axes[i].set_xlabel('Date')\n",
    "    axes[i].set_ylabel('Price ($)')\n",
    "    axes[i].legend()\n",
    "    axes[i].grid(True, alpha=0.3)\n",
    "\n",
    "# Remove extra subplot\n",
    "fig.delaxes(axes[5])\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Quality Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check data quality\n",
    "quality_metrics = {}\n",
    "\n",
    "for symbol, df in stock_data.items():\n",
    "    metrics = collector.validate_data_quality(df)\n",
    "    quality_metrics[symbol] = metrics\n",
    "    \n",
    "    print(f\"\\n{symbol} Data Quality:\")\n",
    "    print(f\"  Total rows: {metrics['total_rows']}\")\n",
    "    print(f\"  Date range: {metrics['date_range'][0]} to {metrics['date_range'][1]}\")\n",
    "    print(f\"  Missing values: {sum(metrics['missing_values'].values())}\")\n",
    "    print(f\"  Zero volume days: {metrics['zero_volumes']}\")\n",
    "    print(f\"  Price anomalies (>50% change): {metrics['price_anomalies']}\")\n",
    "    print(f\"  Data gaps: {len(metrics['data_gaps'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize returns distribution\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, (symbol, df) in enumerate(stock_data.items()):\n",
    "    returns = df['returns'].dropna()\n",
    "    \n",
    "    # Histogram\n",
    "    axes[i].hist(returns, bins=50, alpha=0.7, density=True)\n",
    "    axes[i].axvline(returns.mean(), color='red', linestyle='dashed', linewidth=2, label=f'Mean: {returns.mean():.4f}')\n",
    "    axes[i].axvline(returns.median(), color='green', linestyle='dashed', linewidth=2, label=f'Median: {returns.median():.4f}')\n",
    "    \n",
    "    # Add normal distribution overlay\n",
    "    from scipy import stats\n",
    "    x = np.linspace(returns.min(), returns.max(), 100)\n",
    "    axes[i].plot(x, stats.norm.pdf(x, returns.mean(), returns.std()), 'r-', linewidth=2, label='Normal')\n",
    "    \n",
    "    axes[i].set_title(f'{symbol} Returns Distribution')\n",
    "    axes[i].set_xlabel('Daily Returns')\n",
    "    axes[i].set_ylabel('Density')\n",
    "    axes[i].legend()\n",
    "    axes[i].grid(True, alpha=0.3)\n",
    "\n",
    "fig.delaxes(axes[5])\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Technical Indicators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add technical indicators\n",
    "indicators = TechnicalIndicators()\n",
    "\n",
    "# Process first stock as example\n",
    "symbol = 'AAPL'\n",
    "df_with_indicators = indicators.add_all_indicators(stock_data[symbol].copy())\n",
    "\n",
    "print(f\"Original columns: {len(stock_data[symbol].columns)}\")\n",
    "print(f\"After indicators: {len(df_with_indicators.columns)}\")\n",
    "print(f\"\\nNew indicators added: {len(df_with_indicators.columns) - len(stock_data[symbol].columns)}\")\n",
    "\n",
    "# Show some indicator examples\n",
    "indicator_examples = ['rsi_14', 'macd', 'bb_upper', 'atr_14', 'obv']\n",
    "print(\"\\nSample indicators:\")\n",
    "print(df_with_indicators[indicator_examples].tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize key indicators\n",
    "fig, axes = plt.subplots(4, 1, figsize=(15, 12), sharex=True)\n",
    "\n",
    "# Price with Bollinger Bands\n",
    "axes[0].plot(df_with_indicators.index[-252:], df_with_indicators['close'][-252:], label='Close', linewidth=2)\n",
    "axes[0].plot(df_with_indicators.index[-252:], df_with_indicators['bb_upper'][-252:], 'r--', label='BB Upper', alpha=0.7)\n",
    "axes[0].plot(df_with_indicators.index[-252:], df_with_indicators['bb_lower'][-252:], 'r--', label='BB Lower', alpha=0.7)\n",
    "axes[0].fill_between(df_with_indicators.index[-252:], \n",
    "                     df_with_indicators['bb_lower'][-252:], \n",
    "                     df_with_indicators['bb_upper'][-252:], \n",
    "                     alpha=0.2)\n",
    "axes[0].set_ylabel('Price ($)')\n",
    "axes[0].set_title(f'{symbol} Price with Bollinger Bands (Last Year)')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# RSI\n",
    "axes[1].plot(df_with_indicators.index[-252:], df_with_indicators['rsi_14'][-252:], linewidth=2)\n",
    "axes[1].axhline(y=70, color='r', linestyle='--', alpha=0.7, label='Overbought')\n",
    "axes[1].axhline(y=30, color='g', linestyle='--', alpha=0.7, label='Oversold')\n",
    "axes[1].set_ylabel('RSI')\n",
    "axes[1].set_title('Relative Strength Index (14-day)')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "axes[1].set_ylim(0, 100)\n",
    "\n",
    "# MACD\n",
    "axes[2].plot(df_with_indicators.index[-252:], df_with_indicators['macd'][-252:], label='MACD', linewidth=2)\n",
    "axes[2].plot(df_with_indicators.index[-252:], df_with_indicators['macd_signal'][-252:], label='Signal', linewidth=2)\n",
    "axes[2].bar(df_with_indicators.index[-252:], df_with_indicators['macd_hist'][-252:], label='Histogram', alpha=0.3)\n",
    "axes[2].set_ylabel('MACD')\n",
    "axes[2].set_title('MACD (12, 26, 9)')\n",
    "axes[2].legend()\n",
    "axes[2].grid(True, alpha=0.3)\n",
    "\n",
    "# Volume\n",
    "axes[3].bar(df_with_indicators.index[-252:], df_with_indicators['volume'][-252:], alpha=0.7)\n",
    "axes[3].plot(df_with_indicators.index[-252:], df_with_indicators['volume_sma_20'][-252:], 'r-', label='20-day MA', linewidth=2)\n",
    "axes[3].set_ylabel('Volume')\n",
    "axes[3].set_xlabel('Date')\n",
    "axes[3].set_title('Volume')\n",
    "axes[3].legend()\n",
    "axes[3].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Feature Correlation Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate feature importance/correlation\n",
    "feature_importance = indicators.calculate_feature_importance(\n",
    "    df_with_indicators.dropna(), \n",
    "    target_col='returns'\n",
    ")\n",
    "\n",
    "# Top 20 most correlated features\n",
    "top_features = feature_importance.head(20)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "top_features.plot(kind='barh')\n",
    "plt.title('Top 20 Features by Correlation with Returns')\n",
    "plt.xlabel('Absolute Correlation')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Top 10 most correlated features:\")\n",
    "print(top_features.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation heatmap of selected features\n",
    "selected_features = ['returns', 'volume_ratio', 'rsi_14', 'macd', 'atr_14', \n",
    "                    'bb_pct', 'obv', 'mfi', 'trend_strength', 'high_low_pct']\n",
    "\n",
    "correlation_matrix = df_with_indicators[selected_features].dropna().corr()\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0, \n",
    "            square=True, linewidths=1, cbar_kws={\"shrink\": 0.8})\n",
    "plt.title('Feature Correlation Matrix')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Dataset Creation and Sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataset\n",
    "sequence_length = 60\n",
    "prediction_horizon = 5\n",
    "\n",
    "# Add indicators to all stocks\n",
    "processed_data = {}\n",
    "for symbol, df in stock_data.items():\n",
    "    processed_data[symbol] = indicators.add_all_indicators(df)\n",
    "\n",
    "# Create dataset\n",
    "dataset = StockSequenceDataset(\n",
    "    data=processed_data,\n",
    "    sequence_length=sequence_length,\n",
    "    prediction_horizon=prediction_horizon,\n",
    "    target_column='returns',\n",
    "    scale_features=True,\n",
    "    target_type='regression'\n",
    ")\n",
    "\n",
    "print(f\"Total sequences created: {len(dataset)}\")\n",
    "print(f\"Features used: {len(dataset.get_feature_names())}\")\n",
    "print(f\"\\nFeature names (first 20): {dataset.get_feature_names()[:20]}\")\n",
    "\n",
    "# Sample sequence\n",
    "sample = dataset[0]\n",
    "print(f\"\\nSample sequence shape: {sample['sequence'].shape}\")\n",
    "print(f\"Sample target shape: {sample['target'].shape}\")\n",
    "print(f\"Sample metadata: {sample['metadata']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize a sample sequence\n",
    "sample_idx = 100\n",
    "sample = dataset[sample_idx]\n",
    "sequence = sample['sequence'].numpy()\n",
    "metadata = sample['metadata']\n",
    "\n",
    "# Get feature names\n",
    "feature_names = dataset.get_feature_names()\n",
    "\n",
    "# Plot some key features from the sequence\n",
    "features_to_plot = ['close', 'volume', 'rsi_14', 'macd']\n",
    "feature_indices = [feature_names.index(f) for f in features_to_plot if f in feature_names]\n",
    "\n",
    "fig, axes = plt.subplots(len(feature_indices), 1, figsize=(12, 10), sharex=True)\n",
    "if len(feature_indices) == 1:\n",
    "    axes = [axes]\n",
    "\n",
    "for i, (feat_idx, feat_name) in enumerate(zip(feature_indices, features_to_plot)):\n",
    "    axes[i].plot(sequence[:, feat_idx], linewidth=2)\n",
    "    axes[i].set_ylabel(feat_name)\n",
    "    axes[i].set_title(f'{feat_name} - {metadata[\"symbol\"]}')\n",
    "    axes[i].grid(True, alpha=0.3)\n",
    "\n",
    "axes[-1].set_xlabel('Time Steps')\n",
    "fig.suptitle(f'Sequence from {metadata[\"start_date\"]} to {metadata[\"end_date\"]}\\nTarget Date: {metadata[\"target_date\"]}')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. DataModule Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test DataModule\n",
    "datamodule = StockDataModule(\n",
    "    symbols=symbols,\n",
    "    start_date=start_date,\n",
    "    end_date=end_date,\n",
    "    sequence_length=60,\n",
    "    prediction_horizon=1,\n",
    "    batch_size=32,\n",
    "    target_type='classification',\n",
    "    add_technical_indicators=True,\n",
    "    add_market_data=True,\n",
    "    cache_dir='../data/raw/price_cache'\n",
    ")\n",
    "\n",
    "# Prepare and setup\n",
    "datamodule.prepare_data()\n",
    "datamodule.setup()\n",
    "\n",
    "# Get dataloaders\n",
    "train_loader = datamodule.train_dataloader()\n",
    "val_loader = datamodule.val_dataloader()\n",
    "test_loader = datamodule.test_dataloader()\n",
    "\n",
    "print(f\"Number of features: {datamodule.get_num_features()}\")\n",
    "print(f\"Number of classes: {datamodule.get_num_classes()}\")\n",
    "print(f\"\\nTrain batches: {len(train_loader)}\")\n",
    "print(f\"Val batches: {len(val_loader)}\")\n",
    "print(f\"Test batches: {len(test_loader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check batch\n",
    "batch = next(iter(train_loader))\n",
    "print(\"Batch keys:\", batch.keys())\n",
    "print(f\"Sequence shape: {batch['sequence'].shape}\")\n",
    "print(f\"Target shape: {batch['target'].shape}\")\n",
    "\n",
    "# Target distribution for classification\n",
    "if datamodule.target_type == 'classification':\n",
    "    targets = []\n",
    "    for batch in train_loader:\n",
    "        targets.extend(batch['target'].numpy())\n",
    "    \n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.hist(targets, bins=datamodule.get_num_classes())\n",
    "    plt.xlabel('Class')\n",
    "    plt.ylabel('Count')\n",
    "    plt.title('Target Class Distribution (0=Down, 1=Neutral, 2=Up)')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.show()\n",
    "    \n",
    "    # Class balance\n",
    "    unique, counts = np.unique(targets, return_counts=True)\n",
    "    for cls, count in zip(unique, counts):\n",
    "        print(f\"Class {cls}: {count} samples ({count/len(targets)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics for all stocks\n",
    "summary_stats = pd.DataFrame()\n",
    "\n",
    "for symbol, df in processed_data.items():\n",
    "    stats = {\n",
    "        'Symbol': symbol,\n",
    "        'Days': len(df),\n",
    "        'Start': df.index.min().strftime('%Y-%m-%d'),\n",
    "        'End': df.index.max().strftime('%Y-%m-%d'),\n",
    "        'Avg Return': df['returns'].mean() * 100,\n",
    "        'Volatility': df['returns'].std() * 100,\n",
    "        'Sharpe Ratio': df['returns'].mean() / df['returns'].std() * np.sqrt(252),\n",
    "        'Max Drawdown': (df['close'] / df['close'].cummax() - 1).min() * 100,\n",
    "        'Avg Volume': df['volume'].mean(),\n",
    "        'Price Range': f\"${df['close'].min():.2f} - ${df['close'].max():.2f}\"\n",
    "    }\n",
    "    summary_stats = pd.concat([summary_stats, pd.DataFrame([stats])], ignore_index=True)\n",
    "\n",
    "print(\"Summary Statistics for All Stocks:\")\n",
    "print(summary_stats.to_string(index=False))\n",
    "\n",
    "# Save summary\n",
    "summary_stats.to_csv('../results/data_summary.csv', index=False)\n",
    "print(\"\\nSummary saved to ../results/data_summary.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
